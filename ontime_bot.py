# ontime_bot_with_ai.py
import logging
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from transformers import pipeline

# Configurer le journal
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# Charger le pipeline GPT-like (sarcastique)
sarcastic_generator = pipeline("text-generation", model="gpt2")

# G√©rer la commande /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "Salut ! Je suis ontime_bot, ton bot sarcastique boost√© √† l'IA. Pose-moi une question, et je vais r√©pondre avec mon intelligence sup√©rieure (et un peu de sarcasme). üòè"
    )

# G√©rer les messages avec IA
async def respond(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_message = update.message.text
    try:
        # G√©n√©rer une r√©ponse sarcastique avec GPT
        response = sarcastic_generator(
            f"Fais une r√©ponse sarcastique √† : {user_message}",
            max_length=50,
            num_return_sequences=1,
        )[0]["generated_text"]
        await update.message.reply_text(response)
    except Exception as e:
        logger.error(f"Erreur dans la g√©n√©ration de texte : {e}")
        await update.message.reply_text(
            "Oups ! Je crois que mon cerveau (d'IA) a eu un probl√®me. Essaye encore !"
        )

# Configuration principale
def main():
    token = "7685304448:AAEuMefo6gvKOydyTtRv6pVXLMxvTuJfWr4"  # Votre token ici

    app = ApplicationBuilder().token(token).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, respond))

    app.run_polling()

if __name__ == "__main__":
    main()
